{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4596858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:03:51.596857Z",
     "start_time": "2025-11-11T17:03:51.588060Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "from scipy.signal import find_peaks\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1ff32d",
   "metadata": {},
   "source": [
    "#### Read in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878d9ff",
   "metadata": {},
   "source": [
    "Nur wenn \"gebundelte_eco_counter_fahrradzaehler_bw.xlsx\" noch nicht existiert, ansonsten skippen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeafcd3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:03:43.016324Z",
     "start_time": "2025-11-11T16:53:22.587539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pfad zur Excel-Datei\n",
    "excel_path = \"../data/gebundelte_eco_counter_fahrradzaehler_bw.xlsx\"\n",
    "\n",
    "# Excel-Datei einlesen\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# Zeilen filtern, deren 'data_description' \"CSV\" enthält\n",
    "filtered_df = df[df['data_description'].str.contains(\"CSV\", case=False, na=False)]\n",
    "\n",
    "# URLs extrahieren\n",
    "url_list = filtered_df['data_download_url'].dropna().tolist()\n",
    "\n",
    "# Ausgabe (optional)\n",
    "#for url in url_list:\n",
    "#    print(url)\n",
    "\n",
    "general_columns = pd.read_csv(url_list[1]).columns.tolist()\n",
    "\n",
    "# Erstelle CSV-Datei, in der Daten aller URLs gespeichert werden\n",
    "all_data = pd.DataFrame()\n",
    "for url in url_list:\n",
    "    csv_data = pd.read_csv(url)\n",
    "    assert list(csv_data.columns) == general_columns, f\"Spalten stimmen nicht überein in {url}\"\n",
    "    all_data = pd.concat([all_data, csv_data], ignore_index=True)\n",
    "\n",
    "# Speichere all_data lokal als CSV-Datei\n",
    "all_data.to_csv(\"alle_fahrradzaehler_daten.csv\", index=False)   \n",
    "all_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93fbd19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:06:07.899386Z",
     "start_time": "2025-11-11T17:04:38.936348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>iso_timestamp</th>\n",
       "      <th>zählstand</th>\n",
       "      <th>stand</th>\n",
       "      <th>standort</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>counter_site</th>\n",
       "      <th>counter_site_id</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>timezone</th>\n",
       "      <th>interval</th>\n",
       "      <th>counter_serial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01T01:00:00+0000</td>\n",
       "      <td>2013-01-01T01:00:00+0100</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>752</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "      <td>(UTC+01:00) Europe/Paris;DST</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2H16070301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01T02:00:00+0000</td>\n",
       "      <td>2013-01-01T02:00:00+0100</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>752</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "      <td>(UTC+01:00) Europe/Paris;DST</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2H16070301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01T03:00:00+0000</td>\n",
       "      <td>2013-01-01T03:00:00+0100</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>752</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "      <td>(UTC+01:00) Europe/Paris;DST</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2H16070301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01T04:00:00+0000</td>\n",
       "      <td>2013-01-01T04:00:00+0100</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>752</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "      <td>(UTC+01:00) Europe/Paris;DST</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2H16070301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01T05:00:00+0000</td>\n",
       "      <td>2013-01-01T05:00:00+0100</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>752</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "      <td>(UTC+01:00) Europe/Paris;DST</td>\n",
       "      <td>15</td>\n",
       "      <td>Y2H16070301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp             iso_timestamp  zählstand  stand  \\\n",
       "0  2013-01-01T01:00:00+0000  2013-01-01T01:00:00+0100         15      0   \n",
       "1  2013-01-01T02:00:00+0000  2013-01-01T02:00:00+0100         17      0   \n",
       "2  2013-01-01T03:00:00+0000  2013-01-01T03:00:00+0100         14      0   \n",
       "3  2013-01-01T04:00:00+0000  2013-01-01T04:00:00+0100         13      0   \n",
       "4  2013-01-01T05:00:00+0000  2013-01-01T05:00:00+0100          9      0   \n",
       "\n",
       "          standort    channel_name  channel_id      counter_site  \\\n",
       "0  Stadt Karlsruhe  Erbprinz. West   101004165  Erbprinzenstraße   \n",
       "1  Stadt Karlsruhe  Erbprinz. West   101004165  Erbprinzenstraße   \n",
       "2  Stadt Karlsruhe  Erbprinz. West   101004165  Erbprinzenstraße   \n",
       "3  Stadt Karlsruhe  Erbprinz. West   101004165  Erbprinzenstraße   \n",
       "4  Stadt Karlsruhe  Erbprinz. West   101004165  Erbprinzenstraße   \n",
       "\n",
       "   counter_site_id      domain_name  domain_id  longitude   latitude  \\\n",
       "0        100004165  Stadt Karlsruhe        752   8.402715  49.007286   \n",
       "1        100004165  Stadt Karlsruhe        752   8.402715  49.007286   \n",
       "2        100004165  Stadt Karlsruhe        752   8.402715  49.007286   \n",
       "3        100004165  Stadt Karlsruhe        752   8.402715  49.007286   \n",
       "4        100004165  Stadt Karlsruhe        752   8.402715  49.007286   \n",
       "\n",
       "                       timezone  interval counter_serial  \n",
       "0  (UTC+01:00) Europe/Paris;DST        15    Y2H16070301  \n",
       "1  (UTC+01:00) Europe/Paris;DST        15    Y2H16070301  \n",
       "2  (UTC+01:00) Europe/Paris;DST        15    Y2H16070301  \n",
       "3  (UTC+01:00) Europe/Paris;DST        15    Y2H16070301  \n",
       "4  (UTC+01:00) Europe/Paris;DST        15    Y2H16070301  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Einlesen von alle_fahrradzaehler_daten.csv\n",
    "data = pd.read_csv(\"../data/alle_fahrradzaehler_daten.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239dc21b",
   "metadata": {},
   "source": [
    "#### Check Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78548abf",
   "metadata": {},
   "source": [
    "TODO: Keep relevant checks for submission and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data \n",
    "print(data.info())\n",
    "#print(data.describe())\n",
    "#print(data.isnull().sum())\n",
    "#print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f51a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = data.duplicated()\n",
    "print(f\"Anzahl der Duplikate: {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of years in the dataset\n",
    "data['year'] = data['timestamp'].dt.year\n",
    "print(f\"Jahre im Datensatz: {data['year'].nunique()} - {data['year'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations in data set\n",
    "locations = data['standort'].unique()\n",
    "print(f\"Anzahl der Standorte: {len(locations)}\")\n",
    "print(f\"Standorte:\")\n",
    "for loc in locations:\n",
    "    print(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19cc554",
   "metadata": {},
   "source": [
    "Note: counter = Gerät, channel = Richtung/Messspur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the amount of counters per location\n",
    "counters_per_location = data.groupby('standort').agg(\n",
    "    anzahl_counter=('counter_serial', 'nunique'),\n",
    "    counter_sites=('counter_site', lambda x: ', '.join(sorted(set(x))))\n",
    ").reset_index()\n",
    "\n",
    "print(\"Anzahl der Zähler pro Standort:\") \n",
    "counters_per_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2737e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counters_per_location = data.groupby('standort')['counter_site_id'].nunique()\n",
    "counters_per_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check, at which location (standort) counter_serial is null\n",
    "null_serial_locations = data[data['counter_serial'].isnull()]['standort'].unique()\n",
    "print(f\"Standorte mit null counter_serial: {null_serial_locations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fabd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many channels there are for a counter side\n",
    "channels_per_site = (\n",
    "    data.groupby(['standort', 'counter_site_id'])['channel_name']\n",
    "        .nunique()\n",
    "        .reset_index(name='num_channels')\n",
    ")\n",
    "\n",
    "# Kurze Übersicht\n",
    "print(\"Beschreibung der Anzahl Channels pro Counter-Side:\")\n",
    "print(channels_per_site['num_channels'].describe())\n",
    "print(\"\\nBeispiele:\")\n",
    "print(channels_per_site.head())\n",
    "\n",
    "# Histogramm\n",
    "plt.figure(figsize=(8,4))\n",
    "max_bins = channels_per_site['num_channels'].max()\n",
    "plt.hist(channels_per_site['num_channels'], bins=range(1, max_bins+2), align='left', edgecolor='black')\n",
    "plt.xlabel('Anzahl Channels pro Counter')\n",
    "plt.ylabel('Anzahl Counter')\n",
    "plt.title('Verteilung: Channels pro Counter')\n",
    "plt.xticks(range(1, max_bins+1))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b86ad",
   "metadata": {},
   "source": [
    "##### Check Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check counter per city\n",
    "city = \"Stadt Heilbronn\"\n",
    "data_city = data[data['standort'] == city]\n",
    "print(data_city[\"domain_id\"].unique()[0])\n",
    "counters = data_city[['counter_site', 'counter_site_id', 'counter_serial']].drop_duplicates().reset_index(drop=True)\n",
    "tracking = data_city.groupby(['counter_site', 'counter_site_id', 'counter_serial'], dropna = False)['iso_timestamp'] \\\n",
    "    .agg(first_timestamp='min', last_timestamp='max') \\\n",
    "    .reset_index()\n",
    "counters_with_tracking = counters.merge(tracking, on=['counter_site', 'counter_site_id', 'counter_serial'])\n",
    "counters_with_tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebfb82f",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476a1fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>count</th>\n",
       "      <th>city</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>counter_site_name</th>\n",
       "      <th>counter_site_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 00:00:00+00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 01:00:00+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 02:00:00+00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 03:00:00+00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 04:00:00+00:00</td>\n",
       "      <td>9</td>\n",
       "      <td>Stadt Karlsruhe</td>\n",
       "      <td>Erbprinz. West</td>\n",
       "      <td>101004165</td>\n",
       "      <td>Erbprinzenstraße</td>\n",
       "      <td>100004165</td>\n",
       "      <td>8.402715</td>\n",
       "      <td>49.007286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  count             city    channel_name  \\\n",
       "0 2013-01-01 00:00:00+00:00     15  Stadt Karlsruhe  Erbprinz. West   \n",
       "1 2013-01-01 01:00:00+00:00     17  Stadt Karlsruhe  Erbprinz. West   \n",
       "2 2013-01-01 02:00:00+00:00     14  Stadt Karlsruhe  Erbprinz. West   \n",
       "3 2013-01-01 03:00:00+00:00     13  Stadt Karlsruhe  Erbprinz. West   \n",
       "4 2013-01-01 04:00:00+00:00      9  Stadt Karlsruhe  Erbprinz. West   \n",
       "\n",
       "   channel_id counter_site_name  counter_site_id  longitude   latitude  \n",
       "0   101004165  Erbprinzenstraße        100004165   8.402715  49.007286  \n",
       "1   101004165  Erbprinzenstraße        100004165   8.402715  49.007286  \n",
       "2   101004165  Erbprinzenstraße        100004165   8.402715  49.007286  \n",
       "3   101004165  Erbprinzenstraße        100004165   8.402715  49.007286  \n",
       "4   101004165  Erbprinzenstraße        100004165   8.402715  49.007286  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean data\n",
    "data_cleaned = data.copy()\n",
    "\n",
    "# 1. Time\n",
    "# 'Isotimestamp' is local time and considers 'Sommerzeit'. Therefore, we use this for better accuracy in time representation.\n",
    "# Exchange 'timestemp' with 'iso_timestamp' and convert to datetime with UTC timezone.\n",
    "# Drop 'timezone' as this is identical for all entries.\n",
    "# Drop 'interval' as this is equal for all entries (15 minutes).\n",
    "data_cleaned['timestamp'] = pd.to_datetime(data_cleaned['iso_timestamp'], utc = True, errors='coerce') \n",
    "data_cleaned = data_cleaned.drop(columns=['iso_timestamp', 'timezone', 'interval'])\n",
    "\n",
    "# 2. City\n",
    "# Drop 'domain_name' as this is identical to 'standort'.\n",
    "# Drop 'domain_id' as this is not informative.\n",
    "# Rename 'standort' to 'city' for clarity.\n",
    "data_cleaned = data_cleaned.rename(columns={'standort': 'city'})\n",
    "data_cleaned = data_cleaned.drop(columns=['domain_name', 'domain_id'])\n",
    "\n",
    "# 3. Counter\n",
    "# Drop 'counter_serial' as this is not informative and has many missing values.\n",
    "# Drop 'stand' as this is not informative.\n",
    "# Rename 'counter_site' to 'counter_site_name' for clarity.\n",
    "# Note: For further analysis, use 'counter_site_id' to uniquely identify counter sites.\n",
    "data_cleaned = data_cleaned.rename(columns={'counter_site': 'counter_site_name'})\n",
    "data_cleaned = data_cleaned.drop(columns=['counter_serial', 'stand'])\n",
    "\n",
    "# 4. Channel\n",
    "# TODO: Drop invalid channels (e.g., channel tracking cars, stand?)\n",
    "# Note: For further analysis, use 'channel_id' to uniquely identify channels.\n",
    "\n",
    "# 5. Count\n",
    "# Rename 'zählstand' to 'count' for clarity.\n",
    "data_cleaned = data_cleaned.rename(columns={'zählstand': 'count'})\n",
    "\n",
    "# Save cleaned data\n",
    "data_cleaned.to_csv(\"../data/cleaned_fahrradzaehler_daten.csv\", index=False)\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5dd7eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>median_count</th>\n",
       "      <th>median_count_overall</th>\n",
       "      <th>IQR</th>\n",
       "      <th>normalized_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Landeshauptstadt Stuttgart</td>\n",
       "      <td>2013-01-01 00:00:00+00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-0.322917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Landeshauptstadt Stuttgart</td>\n",
       "      <td>2013-01-01 01:00:00+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-0.364583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Landeshauptstadt Stuttgart</td>\n",
       "      <td>2013-01-01 02:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-0.385417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Landeshauptstadt Stuttgart</td>\n",
       "      <td>2013-01-01 03:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-0.427083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Landeshauptstadt Stuttgart</td>\n",
       "      <td>2013-01-01 04:00:00+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-0.385417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         city                 timestamp  median_count  \\\n",
       "0  Landeshauptstadt Stuttgart 2013-01-01 00:00:00+00:00           5.0   \n",
       "1  Landeshauptstadt Stuttgart 2013-01-01 01:00:00+00:00           3.0   \n",
       "2  Landeshauptstadt Stuttgart 2013-01-01 02:00:00+00:00           2.0   \n",
       "3  Landeshauptstadt Stuttgart 2013-01-01 03:00:00+00:00           0.0   \n",
       "4  Landeshauptstadt Stuttgart 2013-01-01 04:00:00+00:00           2.0   \n",
       "\n",
       "   median_count_overall   IQR  normalized_count  \n",
       "0                  20.5  48.0         -0.322917  \n",
       "1                  20.5  48.0         -0.364583  \n",
       "2                  20.5  48.0         -0.385417  \n",
       "3                  20.5  48.0         -0.427083  \n",
       "4                  20.5  48.0         -0.385417  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Determine median as representative value for each city and normalize data\n",
    "\n",
    "# 1. The hourly count of a counter site is the sum of the counts of all its channels within that hour\n",
    "counter_sum = (\n",
    "    data_cleaned\n",
    "    .groupby([\"city\", \"counter_site_id\", \"timestamp\"])[\"count\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"counter_sum\")\n",
    ")\n",
    "# 2. Compute the median count per hour for each city \n",
    "city_medians = (\n",
    "    counter_sum\n",
    "    .groupby(['city', 'timestamp'])['counter_sum']\n",
    "    .median()\n",
    "    .reset_index(name=\"median_count\")\n",
    ")\n",
    "\n",
    "# 3. Compute the overall median count for each city & IQR\n",
    "yearly_stats = (\n",
    "    city_medians\n",
    "    .groupby(\"city\")[\"median_count\"]\n",
    "    .agg(\n",
    "        median_count_overall=\"median\",\n",
    "        q1=lambda x: x.quantile(0.25),\n",
    "        q3=lambda x: x.quantile(0.75),\n",
    "    )\n",
    ")\n",
    "yearly_stats[\"IQR\"] = yearly_stats[\"q3\"] - yearly_stats[\"q1\"]\n",
    "\n",
    "# 4. Normalize: (x - median_count_overall) / IQR\n",
    "city_norm = city_medians.merge(\n",
    "    yearly_stats[[\"median_count_overall\", \"IQR\"]],\n",
    "    on=\"city\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 5. Avoid division by zero\n",
    "city_norm[\"normalized_count\"] = (\n",
    "    (city_norm[\"median_count\"] - city_norm[\"median_count_overall\"])\n",
    "    .div(city_norm[\"IQR\"].replace(0, pd.NA))\n",
    ")\n",
    "city_norm[\"normalized_count\"] = city_norm[\"normalized_count\"].fillna(0)\n",
    "\n",
    "# Save normalized data\n",
    "city_norm.to_csv(\"../data/normalized_city_fahrradzaehler_daten.csv\", index=False)\n",
    "\n",
    "city_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4eebd8",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a231d",
   "metadata": {},
   "source": [
    "##### Number counts per Location per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16afda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check yearly number of counts per standort \n",
    "\n",
    "# Extract date from timestamp\n",
    "data['date'] = data['timestamp'].dt.date\n",
    "\n",
    "# Step 1: Get max zählstand per standort, counter_serial, and date    #TODO: warum das Maximum extrahieren statt einfach alle zählstände zusammenzuaddieren?\n",
    "max_per_counter = data.groupby(['standort', 'counter_serial', 'date'])['zählstand'].max().reset_index() #TODO: lieber counter_side_id nutzen?\n",
    "\n",
    "# Step 2: Sum these maxima per standort and date\n",
    "daily_counts = max_per_counter.groupby(['standort', 'date'])['zählstand'].sum().reset_index()\n",
    "daily_counts = daily_counts.rename(columns={'zählstand': 'daily_counts'})\n",
    "\n",
    "# Step 3: Now aggregate to yearly counts\n",
    "daily_counts['year'] = pd.to_datetime(daily_counts['date']).dt.year\n",
    "yearly_counts = daily_counts.groupby(['standort', 'year'])['daily_counts'].sum().reset_index()\n",
    "yearly_counts = yearly_counts.rename(columns={'daily_counts': 'yearly_counts'})\n",
    "\n",
    "print(\"Jährliche Zählungen pro Standort:\")\n",
    "yearly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093837be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the yearly counts per standort #TODO: sind das nicht eher die Tages-Maximas aufsummiert und nicht die tatsächlichen counts?\n",
    "def thousands(x, pos):\n",
    "    return f'{int(x/1000)}'\n",
    "\n",
    "standorte = yearly_counts['standort'].unique()\n",
    "colors = cm.get_cmap('tab20', len(standorte))  \n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, standort in enumerate(standorte):\n",
    "    subset = yearly_counts[yearly_counts['standort'] == standort]\n",
    "    plt.plot(subset['year'], subset['yearly_counts'], marker='o', \n",
    "             label=standort, color=colors(i))\n",
    "\n",
    "plt.title(\"Jährliche Fahrradzählungen pro Standort\")\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Anzahl der Fahrradzählungen (in Tsd.)\")\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(thousands))\n",
    "plt.gca().legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e52a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Konstanz, check how many counters there are per year\n",
    "konstanz_data = data[data['standort'] == 'Stadt Konstanz']\n",
    "counters_per_year_konstanz = konstanz_data.groupby('year')['counter_serial'].nunique()\n",
    "counters_per_year_konstanz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of counters per year in Konstanz\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(counters_per_year_konstanz.index, counters_per_year_konstanz.values, marker='o')\n",
    "plt.title(\"Anzahl der Zähler pro Jahr in Konstanz\")\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Anzahl der Zähler\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc65f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize counts per location by number of counters\n",
    "\n",
    "# First, calculate number of active counters per standort and date i.e. counters that have non-null zählstand on that date as max value\n",
    "active_counters = data.groupby(['standort', 'counter_serial', 'date'])['zählstand'].max().reset_index()\n",
    "active_counters = active_counters[active_counters['zählstand'].notnull()]\n",
    "active_counters = active_counters.groupby(['standort', 'date'])['counter_serial'].nunique().reset_index()\n",
    "active_counters = active_counters.rename(columns={'counter_serial': 'num_active_counters'})\n",
    "\n",
    "# Merge mit daily_counts\n",
    "daily_counts = daily_counts.merge(active_counters, on=['standort', 'date'], how='left')\n",
    "\n",
    "# Normalize daily counts\n",
    "daily_counts['normalized_daily_counts'] = daily_counts['daily_counts'] / daily_counts['num_active_counters']\n",
    "\n",
    "\n",
    "# Aggregate to yearly normalized counts\n",
    "normalized_yearly_counts = daily_counts.groupby(['standort', 'year'])['normalized_daily_counts'].sum().reset_index()\n",
    "normalized_yearly_counts = normalized_yearly_counts.rename(columns={'normalized_daily_counts': 'normalized_yearly_counts'})\n",
    "\n",
    "print(\"Normalisierte jährliche Zählungen pro Standort:\")\n",
    "normalized_yearly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normalized yearly counts per standort\n",
    "def thousands(x, pos):\n",
    "    return f'{int(x/1000)}'\n",
    "\n",
    "standorte = normalized_yearly_counts['standort'].unique()\n",
    "colors = cm.get_cmap('tab20', len(standorte))  # Colormap\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, standort in enumerate(standorte):\n",
    "    subset = normalized_yearly_counts[normalized_yearly_counts['standort'] == standort]\n",
    "    plt.plot(subset['year'], subset['normalized_yearly_counts'], marker='o',  # hier die Jahreswerte verwenden!\n",
    "             label=standort, color=colors(i))\n",
    "\n",
    "plt.title(\"Jährliche Fahrradzählungen pro Standort (normalisiert)\")\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Anzahl der Fahrradzählungen/# Aktive Tracker (in Tsd.)\")\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(thousands))\n",
    "plt.gca().legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printe für jeden Standort die Anzahl der Datenpunkte\n",
    "for location in data['standort'].unique():\n",
    "    count = data[(data['standort'] == location)].shape[0]\n",
    "    if count > 0:\n",
    "        print(f\"Standort: {location}, Anzahl der Datenpunkte: {count}\")\n",
    "\n",
    "#printe für jeden Standort alle Channel-Namen:\n",
    "for location in data['standort'].unique():\n",
    "    channel_names = data[data['standort'] == location]['channel_name'].unique()\n",
    "    print(f\"Standort: {location}, Channel Names: {channel_names}\")\n",
    "\n",
    "# printe für jeden Channel Name am Standort Stadt Freiburg die Anzahl der Datenpunkte:\n",
    "for channel_name in data['channel_name'].unique():\n",
    "    count = data[(data['standort'] == \"Stadt Freiburg\") & (data['channel_name'] == channel_name)].shape[0]\n",
    "    if count > 0:\n",
    "        print(f\"Standort: Stadt Freiburg, Channel Name: {channel_name}, Anzahl der Datenpunkte: {count}\")\n",
    "\n",
    "\"\"\"for location in data['standort'].unique():\n",
    "    for channel_name in data['channel_name'].unique():\n",
    "        count = data[(data['standort'] == location) & (data['channel_name'] == channel_name)].shape[0]\n",
    "        if count > 0:\n",
    "            print(f\"Standort: {location}, Channel Name: {channel_name}, Anzahl der Datenpunkte: {count}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30466f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prüfe, für jeden Standort, wie viele Datenpunkte es gibt \n",
    "#for location in data['standort'].unique():\n",
    "location = \"Stadt Freiburg\"\n",
    "for site_id in data['counter_site_id'].unique():\n",
    "    count = data[(data['standort'] == location) & (data['counter_site_id'] == site_id)].shape[0]\n",
    "    if count > 0:\n",
    "        print(f\"Standort: {location}, Counter Side ID: {site_id}, Anzahl der Datenpunkte: {count}\")\n",
    "\n",
    "for channel_name in data['channel_name'].unique():\n",
    "    count = data[(data['standort'] == location) & (data['channel_name'] == channel_name)].shape[0]\n",
    "    if count > 0:\n",
    "        print(f\"Standort: {location}, Channel Name: {channel_name}, Anzahl der Datenpunkte: {count}\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printe für jeden Standort, Channel Name und Counter Site ID die Anzahl der Datenpunkte\n",
    "for location in data['standort'].unique():\n",
    "    data_standort = data[data['standort'] == location]\n",
    "    for site_id in data_standort['counter_site_id'].unique():\n",
    "        for channel_name in data_standort['channel_name'].unique():\n",
    "            count = data[(data['standort'] == location) & (data['counter_site_id'] == site_id) & (data['channel_name'] == channel_name)].shape[0]\n",
    "            if count > 0:\n",
    "                print(f\"Standort: {location}, Channel Name: {channel_name}, Counter Side ID: {site_id}, Anzahl der Datenpunkte: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# prüfe für jeden Counter (Kombination aus Standort, Channel_name und Counter_Site_ID), \n",
    "# was der jeweils früheste und späteste timestamp ist\n",
    "# schreibe standort, channel_name, frühester und spätester timestamp in pandas dataframe\n",
    "start_end_timestamps = pd.DataFrame(columns=['standort', 'channel_name', 'counter_site_id', 'earliest_timestamp', 'latest_timestamp'])\n",
    "\n",
    "for location in data['standort'].unique():\n",
    "    data_standort = data[data['standort'] == location]\n",
    "    for site_id in data_standort['counter_site_id'].unique():\n",
    "        for channel_name in data_standort['channel_name'].unique():\n",
    "            subset = data[(data['standort'] == location) & (data['counter_site_id'] == site_id) & (data['channel_name'] == channel_name)]\n",
    "            if not subset.empty:\n",
    "                earliest = subset['timestamp'].min().replace(tzinfo=None)\n",
    "                latest = subset['timestamp'].max().replace(tzinfo=None)\n",
    "\n",
    "                start_end_timestamps = pd.concat([start_end_timestamps, pd.DataFrame([{\n",
    "                    'standort': location,\n",
    "                    'channel_name': channel_name,\n",
    "                    'counter_site_id': site_id,\n",
    "                    'earliest_timestamp': earliest,\n",
    "                    'latest_timestamp': latest\n",
    "                }])], ignore_index=True)                       \n",
    "                \n",
    "    print(location)\n",
    "                \n",
    "    \"\"\"if earliest > datetime(2013, 1, 1, 1, 0, 0) or latest < datetime(2024, 12, 31, 23, 0, 0):\n",
    "    #datetime(2023, 11, 7, 14, 30, 0)  # Jahr, Monat, Tag, Stunde, Minute, Sekunde\n",
    "        print(f\"{location}, {channel_name}, Frühester Timestamp: {earliest}, Spätester Timestamp: {latest}\")\n",
    "    else:\n",
    "        print(f\"{location}, {channel_name}, passt zeitlich\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schreibe start_end_timestamps in csv-datei\n",
    "start_end_timestamps.to_csv(\"start_end_timestamps.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_literacy_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
