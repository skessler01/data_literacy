{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T11:00:44.633589Z",
     "start_time": "2025-12-23T11:00:33.520236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import MSTL\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from utils.weather_data import merge_bike_weather, download_corresponding_weather_data\n",
    "import time\n",
    "from utils.mstl_utils import performMSTL, plotMSTLResults\n",
    "d = pd.read_csv(\"../../data/cleaned_full_data.csv\")"
   ],
   "id": "b70479aa1186cd60",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grube\\AppData\\Local\\Temp\\ipykernel_16252\\766483904.py:12: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  d = pd.read_csv(\"../data/cleaned_full_data.csv\")\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = d.copy()\n",
    "# --- 1. FILTER ONE CITY ---\n",
    "city = \"Stadt Tübingen\"\n",
    "df_city = df[df[\"city\"] == city].copy()\n",
    "\n",
    "# Ensure timestamp is datetime and sorted\n",
    "df_city[\"timestamp\"] = pd.to_datetime(df_city[\"timestamp\"])\n",
    "df_city = df_city.sort_values(\"timestamp\")\n",
    "\n",
    "# Set index\n",
    "df_city = df_city.set_index(\"timestamp\")\n",
    "\n",
    "# --- 2. RESAMPLE TO ENSURE HOURLY REGULARITY ---\n",
    "# (forward fill or leave gaps if you prefer Lomb-Scargle later)\n",
    "ts = df_city[\"median_count\"].asfreq(\"H\")\n",
    "\n",
    "# Optionally fill small gaps:\n",
    "ts = ts.interpolate()\n",
    "\n",
    "# Convert to numpy\n",
    "x = ts.values\n",
    "n = len(x)\n",
    "dt = 1  # sampling interval = 1 hour\n",
    "\n",
    "# --- 3. FAST FOURIER TRANSFORM (FFT) ---\n",
    "fft_vals = np.fft.rfft(x - np.mean(x))  # remove mean\n",
    "fft_freq = np.fft.rfftfreq(n, d=dt)  # frequency in cycles per hour\n",
    "\n",
    "# Power spectrum\n",
    "power = np.abs(fft_vals) ** 2\n",
    "\n",
    "# --- 4. CONVERT FREQUENCIES TO PERIODS ---\n",
    "# Avoid division by zero\n",
    "periods = np.where(fft_freq == 0, np.inf, 1 / fft_freq)\n",
    "\n",
    "# --- 5. PLOT ---\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(periods, power)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Period (hours, log scale)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(f\"FFT Spectrum – {city}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print top peaks for interpretation\n",
    "idx_peaks = np.argsort(power)[-15:]  # 10 strongest frequencies\n",
    "peaks = pd.DataFrame({\n",
    "    \"frequency (cycles/hour)\": fft_freq[idx_peaks],\n",
    "    \"period (hours)\": periods[idx_peaks],\n",
    "    \"power\": power[idx_peaks]\n",
    "}).sort_values(\"period (hours)\")\n",
    "\n",
    "peaks"
   ],
   "id": "f3aaa9574194c81f",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ----- download corresponding weather data and merge it with data -----\n",
    "data = pd.read_csv(\"../../data/cleaned_full_data.csv\")\n",
    "weather_data = download_corresponding_weather_data(data)\n",
    "full_data = merge_bike_weather(data, weather_data)\n",
    "full_data.to_csv(\"../data/combined_data.csv\", index=False)\n",
    "\n",
    "full_data.head()"
   ],
   "id": "613d95182d06d127",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d = pd.read_csv(\"combined_data.csv\")\n",
    "df = d.copy()\n",
    "city = \"Stadt Konstanz\"\n",
    "df_city = df[df[\"city\"] == city].copy()\n",
    "df_city[\"timestamp\"] = pd.to_datetime(df_city[\"timestamp\"])\n",
    "df_city = df_city.set_index(\"timestamp\")\n",
    "ts = df_city[\"median_count\"].asfreq(\"h\")\n",
    "ts = ts.interpolate()\n",
    "periods = [24, 168, 8766]\n",
    "\n",
    "m = MSTL(ts, periods=periods)\n",
    "res = m.fit()\n",
    "res.plot()\n",
    "\n",
    "res_konstanz = pd.DataFrame({'trend': res.trend, 'residual': res.resid})\n",
    "for key in res.seasonal:\n",
    "    res_konstanz[key] = res.seasonal[key]\n",
    "\n",
    "res_konstanz['city'] = \"Stadt Konstanz\"\n",
    "res_konstanz.to_csv(\"konstanz_mstl.csv\", index=True)\n",
    "print(res_konstanz.head())"
   ],
   "id": "7e72a5e47fcadb22",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "daily_seasonal = res.seasonal['seasonal_24']\n",
    "daily_pattern = daily_seasonal.groupby(daily_seasonal.index.hour).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(daily_pattern, marker='o')\n",
    "plt.title(f\"Average Daily Pattern – {city}\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Seasonal Effect (Bike Counts)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Split data\n",
    "weekday_data = ts[ts.index.weekday < 5]  # Monday-Friday\n",
    "saturday_data = ts[ts.index.weekday == 5]\n",
    "sunday_data = ts[ts.index.weekday == 6]\n",
    "\n",
    "# Compute hourly average for each group\n",
    "daily_pattern_weekday = weekday_data.groupby(weekday_data.index.hour).mean()\n",
    "daily_pattern_saturday = saturday_data.groupby(saturday_data.index.hour).mean()\n",
    "daily_pattern_sunday = sunday_data.groupby(sunday_data.index.hour).mean()\n",
    "\n",
    "# Plot together\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(daily_pattern_weekday, marker='o', label='Weekdays')\n",
    "plt.plot(daily_pattern_saturday, marker='o', label='Saturday')\n",
    "plt.plot(daily_pattern_sunday, marker='o', label='Sunday')\n",
    "plt.title(f\"Average Daily Bike Pattern – {city}\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Median Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "weekly_seasonal = res.seasonal['seasonal_168']\n",
    "weekly_pattern = weekly_seasonal.groupby(weekly_seasonal.index.dayofweek).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(7), weekly_pattern)\n",
    "plt.xticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.title(f\"Average Weekly Pattern – {city}\")\n",
    "plt.ylabel(\"Seasonal Effect\")\n",
    "plt.show()\n",
    "yearly_seasonal = res.seasonal['seasonal_8766']\n",
    "# Aggregate by month\n",
    "yearly_pattern = yearly_seasonal.groupby(yearly_seasonal.index.month).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 13), yearly_pattern, marker='o')\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title(f\"Average Monthly Pattern – {city}\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Seasonal Effect\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(res.trend)\n",
    "plt.title(f\"Long-term Trend – {city}\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Bike Counts (Trend)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(res.resid)\n",
    "plt.title(f\"Residuals – {city}\")\n",
    "plt.show()\n",
    "\n",
    "# Check autocorrelation\n",
    "plot_acf(res.resid, lags=48)\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(res.resid, lags=48)\n",
    "plt.show()\n",
    "y = res.resid  # assuming res is MSTL result\n"
   ],
   "id": "73f995844e67cc58",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# --- 2. Weather features ---\n",
    "# Ensure timestamp index is datetime and tz-aware\n",
    "df_city.index = pd.to_datetime(df_city.index).tz_convert('UTC')\n",
    "\n",
    "# Select weather columns\n",
    "weather_cols = ['temperature_2m', 'apparent_temperature', 'rain', 'snowfall']\n",
    "X = df_city[weather_cols].reindex(y.index)  # align to residuals\n",
    "\n",
    "# Drop rows with any missing values\n",
    "mask = X.notna().all(axis=1)\n",
    "X_clean = X[mask]\n",
    "y_clean = y[mask]\n",
    "\n",
    "print(f'Aligned length: {len(y_clean)}')\n",
    "print(y_clean.index.equals(X_clean.index))  # should be True\n",
    "\n",
    "# --- 3. Add nonlinear features (optional) ---\n",
    "X_clean['temp_sq'] = X_clean['temperature_2m'] ** 2\n",
    "X_clean['rain_binary'] = (X_clean['rain'] > 0).astype(int)\n",
    "X_clean['snow_binary'] = (X_clean['snowfall'] > 0).astype(int)\n",
    "\n",
    "# --- 4. Fit linear regression ---\n",
    "X_reg = sm.add_constant(X_clean)\n",
    "model = sm.OLS(y_clean, X_reg).fit()\n",
    "print(model.summary())\n"
   ],
   "id": "ffe7c50d74995675",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "weather_effect = model.predict(X_reg)\n",
    "y_deseasoned_dweath = y_clean - weather_effect\n",
    "\n",
    "# --- Plot MSTL residuals vs weather-cleaned residuals ---\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.plot(y_clean, label='Residuals (MSTL)', color='skyblue', alpha=0.6)\n",
    "plt.plot(y_deseasoned_dweath, label='After weather adjustment', color='darkorange', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Residuals (bike count)')\n",
    "plt.title('MSTL Residuals vs Weather-Cleaned Residuals')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# Identify rain events\n",
    "rain_times = X_clean[X_clean['rain'] > 0].index\n",
    "snow_times = X_clean[X_clean['snow_binary'] > 0].index\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(y_deseasoned_dweath, label='Weather-cleaned residuals', color='darkorange')\n",
    "\n",
    "# Shade rain periods\n",
    "plt.scatter(rain_times, y_deseasoned_dweath.loc[rain_times], color='blue', s=10, label='Rain')\n",
    "\n",
    "# Shade snow periods\n",
    "plt.scatter(snow_times, y_deseasoned_dweath.loc[snow_times], color='purple', s=10, label='Snow')\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Residuals (bike count)')\n",
    "plt.title('Residuals After Weather Removal with Rain/Snow Events')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "a8fe647e4da6b22c",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = d.copy()\n",
    "city_f = \"Stadt Freiburg\"\n",
    "df_city_f = df[df[\"city\"] == city_f].copy()\n",
    "df_city_f[\"timestamp\"] = pd.to_datetime(df_city_f[\"timestamp\"])\n",
    "df_city_f = df_city_f.set_index(\"timestamp\")\n",
    "ts_f = df_city_f[\"median_count\"].asfreq(\"h\")\n",
    "ts_f = ts_f.interpolate()\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "y = ts_f  # time-indexed, hourly Series\n",
    "y_shifted = y + 1  # Box–Cox requires positive values\n",
    "\n",
    "y_bc_values, lambda_bc = boxcox(y_shifted.values)\n",
    "\n",
    "y_bc = pd.Series(\n",
    "    y_bc_values,\n",
    "    index=y.index,\n",
    "    name=\"median_count_bc\"\n",
    ")\n",
    "print(lambda_bc)\n",
    "print(y_bc)"
   ],
   "id": "a187fa7e43006f9e",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "periods = [24, 168, 8766]\n",
    "m = MSTL(y_bc, periods=periods)\n",
    "res = m.fit()\n",
    "res.plot()\n"
   ],
   "id": "e8a7b484aa96d42b",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "periods = [24, 168, 8766]\n",
    "\n",
    "m = MSTL(ts_f, periods=periods)\n",
    "res = m.fit()\n",
    "res_freiburg = pd.DataFrame({'trend': res.trend, 'residual': res.resid})\n",
    "for key in res.seasonal:\n",
    "    res_freiburg[key] = res.seasonal[key]\n",
    "\n",
    "res_freiburg['city'] = \"Stadt Freiburg\"\n",
    "res_freiburg.to_csv(\"freiburg_mstl.csv\", index=True)\n",
    "res.plot()"
   ],
   "id": "5969f940115f8a96",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "city = \"Stadt Freiburg\"\n",
    "daily_seasonal = res.seasonal['seasonal_24']\n",
    "daily_pattern = daily_seasonal.groupby(daily_seasonal.index.hour).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(daily_pattern, marker='o')\n",
    "plt.title(f\"Average Daily Pattern – {city}\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Seasonal Effect (Bike Counts)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Split data\n",
    "weekday_data = ts_f[ts_f.index.weekday < 5]  # Monday-Friday\n",
    "saturday_data = ts_f[ts_f.index.weekday == 5]\n",
    "sunday_data = ts_f[ts_f.index.weekday == 6]\n",
    "\n",
    "# Compute hourly average for each group\n",
    "daily_pattern_weekday = weekday_data.groupby(weekday_data.index.hour).mean()\n",
    "daily_pattern_saturday = saturday_data.groupby(saturday_data.index.hour).mean()\n",
    "daily_pattern_sunday = sunday_data.groupby(sunday_data.index.hour).mean()\n",
    "\n",
    "# Plot together\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(daily_pattern_weekday, marker='o', label='Weekdays')\n",
    "plt.plot(daily_pattern_saturday, marker='o', label='Saturday')\n",
    "plt.plot(daily_pattern_sunday, marker='o', label='Sunday')\n",
    "plt.title(f\"Average Daily Bike Pattern – Stadt Freiburg\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Median Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "weekly_seasonal = res.seasonal['seasonal_168']\n",
    "weekly_pattern = weekly_seasonal.groupby(weekly_seasonal.index.dayofweek).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(7), weekly_pattern)\n",
    "plt.xticks(range(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "plt.title(f\"Average Weekly Pattern – Stadt Freiburg\")\n",
    "plt.ylabel(\"Seasonal Effect\")\n",
    "plt.show()\n",
    "yearly_seasonal = res.seasonal['seasonal_8766']\n",
    "# Aggregate by month\n",
    "yearly_pattern = yearly_seasonal.groupby(yearly_seasonal.index.month).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 13), yearly_pattern, marker='o')\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title(f\"Average Monthly Pattern – Stadt Freiburg\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Seasonal Effect\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(res.trend)\n",
    "plt.title(f\"Long-term Trend – {city}\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Bike Counts (Trend)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(res.resid)\n",
    "plt.title(f\"Residuals – Stadt Freiburg\")\n",
    "plt.show()\n",
    "\n",
    "# Check autocorrelation\n",
    "plot_acf(res.resid, lags=48)\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(res.resid, lags=48)\n",
    "plt.show()"
   ],
   "id": "efb9ec7b25c5bb34",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# perform MSTL on all cities and save the results\n",
    "df = pd.read_csv(\"combined_data.csv\")\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "cities = df[\"city\"].unique()\n",
    "periods = [24, 168, 8766]\n",
    "mstl_results = {}\n",
    "for city in cities:\n",
    "    print(\"Processing\", city)\n",
    "    df_city = df[df[\"city\"] == city].copy()\n",
    "    df_city = df_city.sort_values(\"timestamp\")\n",
    "    df_city = df_city.set_index(\"timestamp\")\n",
    "    ts = df_city[\"normalized_count\"].asfreq(\"h\")\n",
    "    ts = ts.interpolate()\n",
    "\n",
    "    m = MSTL(ts, periods=periods)\n",
    "    res = m.fit()\n",
    "\n",
    "    df_res = pd.DataFrame({\n",
    "        \"trend\": res.trend,\n",
    "        \"residual\": res.resid,\n",
    "        \"seasonal_24\": res.seasonal[\"seasonal_24\"],\n",
    "        \"seasonal_168\": res.seasonal[\"seasonal_168\"],\n",
    "        \"seasonal_8766\": res.seasonal[\"seasonal_8766\"],\n",
    "    }, index=ts.index)\n",
    "    df_res[\"city\"] = city\n",
    "    df_res.to_csv(\"res_{}.csv\".format(city), index=True)\n",
    "\n",
    "    mstl_results[city] = res\n",
    "    res.plot()\n",
    "    print(f\"Saved results for city {city}\")"
   ],
   "id": "4264ffd967fc1336",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d_res = pd.read_csv(\"data/mstl_results/res_Stadt Freiburg.csv\")\n",
    "d_res[\"timestamp\"] = pd.to_datetime(d_res[\"timestamp\"], utc=True)\n",
    "day = 5\n",
    "year = 2022\n",
    "month = 7\n",
    "# Filter the rows where the timestamp corresponds to the specific day\n",
    "filtered_data = d_res[\n",
    "    (d_res[\"timestamp\"].dt.year == year) &\n",
    "    (d_res[\"timestamp\"].dt.month == month) &\n",
    "    (d_res[\"timestamp\"].dt.day == day)\n",
    "    ].copy()\n",
    "filtered_data = filtered_data[['timestamp', 'seasonal_24']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_data[\"timestamp\"], filtered_data[\"seasonal_24\"], marker='o')\n",
    "plt.title(f\"Daily Bike Pattern – Stadt Freiburg ({year}-{month}-{day})\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Seasonal_24 Value\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "day = 1\n",
    "year = 2022\n",
    "month = 11\n",
    "# Filter the rows where the timestamp corresponds to the specific day\n",
    "filtered_data = d_res[\n",
    "    (d_res[\"timestamp\"].dt.year == year) &\n",
    "    (d_res[\"timestamp\"].dt.month == month) &\n",
    "    (d_res[\"timestamp\"].dt.day == day)\n",
    "    ].copy()\n",
    "filtered_data = filtered_data[['timestamp', 'seasonal_24']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_data[\"timestamp\"], filtered_data[\"seasonal_24\"], marker='o')\n",
    "plt.title(f\"Daily Bike Pattern – Stadt Freiburg ({year}-{month}-{day})\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Seasonal_24 Value\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "day = 1\n",
    "year = 2022\n",
    "month = 3\n",
    "# Filter the rows where the timestamp corresponds to the specific day\n",
    "filtered_data = d_res[\n",
    "    (d_res[\"timestamp\"].dt.year == year) &\n",
    "    (d_res[\"timestamp\"].dt.month == month) &\n",
    "    (d_res[\"timestamp\"].dt.day == day)\n",
    "    ].copy()\n",
    "filtered_data = filtered_data[['timestamp', 'seasonal_24']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_data[\"timestamp\"], filtered_data[\"seasonal_24\"], marker='o')\n",
    "plt.title(f\"Daily Bike Pattern – Stadt Freiburg ({year}-{month}-{day})\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Seasonal_24 Value\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Months you want to compare\n",
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "year = 2022\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for month in months:\n",
    "    # Filter that month\n",
    "    df = d_res[\n",
    "        (d_res[\"timestamp\"].dt.year == year) &\n",
    "        (d_res[\"timestamp\"].dt.month == month)\n",
    "        ].copy()\n",
    "\n",
    "    # Keep only needed columns\n",
    "    df = df[[\"timestamp\", \"seasonal_168\"]]\n",
    "\n",
    "    # Extract hour within the weekly cycle 0–167\n",
    "    df[\"hour_of_week\"] = (\n",
    "            df[\"timestamp\"].dt.dayofweek * 24 +\n",
    "            df[\"timestamp\"].dt.hour\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    plt.plot(df[\"hour_of_week\"], df[\"seasonal_168\"], label=f\"{year}-{month:02d}\")\n",
    "\n",
    "plt.title(\"Weekly Bike Pattern (seasonal_168) – Stadt Freiburg\")\n",
    "plt.xlabel(\"Hour of Week (0–167)\")\n",
    "plt.ylabel(\"seasonal_168 Value\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Months to compare\n",
    "months = range(1, 13)\n",
    "year = 2022\n",
    "day = 15\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loop through each month\n",
    "for month in months:\n",
    "    # Filter the data for the 15th day of each month\n",
    "    filtered_data = d_res[\n",
    "        (d_res[\"timestamp\"].dt.year == year) &\n",
    "        (d_res[\"timestamp\"].dt.month == month) &\n",
    "        (d_res[\"timestamp\"].dt.day == day)\n",
    "        ].copy()\n",
    "\n",
    "    # Keep only the necessary columns\n",
    "    filtered_data = filtered_data[['timestamp', 'seasonal_24']]\n",
    "\n",
    "    # Extract hour of day (0–23)\n",
    "    filtered_data[\"hour_of_day\"] = filtered_data[\"timestamp\"].dt.hour\n",
    "\n",
    "    # Plot the data with hour_of_day on the x-axis\n",
    "    plt.plot(filtered_data[\"hour_of_day\"], filtered_data[\"seasonal_24\"], marker='o', label=f\"{year}-{month:02d}\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(f\"Bike Pattern on 15th Day of Each Month – Stadt Freiburg ({year})\")\n",
    "plt.xlabel(\"Hour of Day (0–23)\")\n",
    "plt.ylabel(\"Seasonal_24 Value\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Month\")\n",
    "plt.xticks(range(24))  # Show every hour on the x-axis (0–23)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define the seasons\n",
    "seasons = {\n",
    "    'Winter': [12, 1, 2],  # December, January, February\n",
    "    'Spring': [3, 4, 5],  # March, April, May\n",
    "    'Summer': [6, 7, 8],  # June, July, August\n",
    "    'Autumn': [9, 10, 11]  # September, October, November\n",
    "}\n",
    "\n",
    "# Create the figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loop through each season\n",
    "for season, months in seasons.items():\n",
    "    # Filter the data for the specified months in the season\n",
    "    season_data = d_res[d_res[\"timestamp\"].dt.month.isin(months)].copy()\n",
    "\n",
    "    # Keep only necessary columns\n",
    "    season_data = season_data[['timestamp', 'seasonal_24']]\n",
    "\n",
    "    # Extract hour of day (0–23)\n",
    "    season_data[\"hour_of_day\"] = season_data[\"timestamp\"].dt.hour\n",
    "\n",
    "    # Group by hour_of_day and calculate the average seasonal_24 value for each hour\n",
    "    avg_season_data = season_data.groupby(\"hour_of_day\")[\"seasonal_24\"].mean()\n",
    "\n",
    "    # Plot the average seasonal_24 values for each season\n",
    "    plt.plot(avg_season_data.index, avg_season_data.values, label=season, marker='o')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Average Bike Pattern by Season – Stadt Freiburg (2022)\")\n",
    "plt.xlabel(\"Hour of Day (0–23)\")\n",
    "plt.ylabel(\"Average Seasonal_24 Value\")\n",
    "plt.grid(True)\n",
    "plt.legend(title=\"Season\")\n",
    "plt.xticks(range(24))  # Show every hour on the x-axis (0–23)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b393567ff2a38ee6",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "actual_data = pd.read_csv(\"combined_data.csv\")\n",
    "actual_data[\"timestamp\"] = pd.to_datetime(actual_data[\"timestamp\"], utc=True)\n",
    "\n",
    "# Load the MSTL results (res_Stadt Freiburg.csv)\n",
    "mstl_data = pd.read_csv(\"data/mstl_results/res_Stadt Freiburg.csv\")\n",
    "mstl_data[\"timestamp\"] = pd.to_datetime(mstl_data[\"timestamp\"], utc=True)\n",
    "\n",
    "# Filter for 'Stadt Freiburg' city and make sure we have matching timestamps\n",
    "actual_data_freiburg = actual_data[actual_data['city'] == 'Stadt Freiburg']\n",
    "mstl_data_freiburg = mstl_data[mstl_data['city'] == 'Stadt Freiburg']\n",
    "\n",
    "# Merge both datasets based on the timestamp\n",
    "merged_data = pd.merge(actual_data_freiburg, mstl_data_freiburg, on=\"timestamp\", how=\"inner\")\n",
    "\n",
    "# Calculate the sum of MSTL components (trend + residual + seasonal_24)\n",
    "merged_data['mstl_sum'] = merged_data['trend'] + merged_data['seasonal_24'] + merged_data['seasonal_168'] + merged_data[\n",
    "    'seasonal_8766']\n",
    "\n",
    "# Plot the actual values vs the sum of MSTL components\n",
    "plt.figure(figsize=(100, 10))\n",
    "\n",
    "# Plot actual normalized_count\n",
    "plt.plot(merged_data[\"timestamp\"], merged_data[\"normalized_count\"], label=\"Actual Values (normalized_count)\",\n",
    "         marker='o', linestyle='-', color='blue', alpha=0.5)\n",
    "\n",
    "# Plot the sum of MSTL components\n",
    "plt.plot(merged_data[\"timestamp\"], merged_data[\"mstl_sum\"],\n",
    "         label=\"Sum of MSTL Components (trend + residual + seasonal_24)\", marker='o', linestyle='-', color='red',\n",
    "         alpha=0.5)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title(\"Comparison of Actual Bike Counts vs MSTL Decomposed Sum – Stadt Freiburg\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Bike Count / MSTL Sum\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "70e86721af052bcc",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "csv_files = [\n",
    "    \"res_Landeshauptstadt Stuttgart.csv\",\n",
    "    \"res_Ravensburg TWS GmbH and Co KG.csv\",\n",
    "    \"res_Stadt Freiburg.csv\",\n",
    "    \"res_Stadt Heidelberg.csv\",\n",
    "    \"res_Stadt Heilbronn.csv\",\n",
    "    \"res_Stadt Karlsruhe.csv\",\n",
    "    \"res_Stadt Kirchheim unter Teck.csv\",\n",
    "    \"res_Stadt Konstanz.csv\",\n",
    "    \"res_Stadt Ludwisburg.csv\",\n",
    "    \"res_Stadt Lörrach.csv\",\n",
    "    \"res_Stadt Mannheim.csv\",\n",
    "    \"res_Stadt Offenburg.csv\",\n",
    "    \"res_Stadt Reutlingen.csv\",\n",
    "    \"res_Stadt Singen.csv\",\n",
    "    \"res_Stadt Tübingen.csv\",\n",
    "    \"res_Stadt Ulm.csv\",\n",
    "    #\"res_Stadtverwaltung Aalen.csv\"\n",
    "    \"res_Landkreis Böblingen.csv\"\n",
    "    #\"res_Landratsamt Rems-Murr-Kreis.csv\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Loop through each city file\n",
    "for file in csv_files:\n",
    "    city = file.replace(\"res_\", \"\").replace(\".csv\", \"\")  # Extract city name from filename\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(\"../data/mstl_results/\" + file)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    # Extract the daily seasonal component\n",
    "    daily_seasonal = df[\"seasonal_24\"]\n",
    "\n",
    "    # Create a DataFrame with hour of day\n",
    "    df_daily = pd.DataFrame({\n",
    "        \"hour\": df[\"timestamp\"].dt.hour,\n",
    "        \"seasonal_24\": daily_seasonal\n",
    "    })\n",
    "\n",
    "    # Calculate the average value per hour\n",
    "    daily_pattern = df_daily.groupby(\"hour\")[\"seasonal_24\"].mean()\n",
    "\n",
    "    # Plot the city's average daily pattern\n",
    "    plt.plot(daily_pattern.index, daily_pattern.values, marker='o', label=city, alpha=0.7)\n",
    "\n",
    "# Finalize the plot\n",
    "plt.title(\"Average Daily Bike Pattern Across Cities\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Average Seasonal_24 Effect\")\n",
    "plt.xticks(range(24))\n",
    "plt.grid(True)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Put legend outside plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "fa7caf630cc5509",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "csv_files = [\n",
    "    \"res_Landeshauptstadt Stuttgart.csv\",\n",
    "    \"res_Ravensburg TWS GmbH and Co KG.csv\",\n",
    "    \"res_Stadt Freiburg.csv\",\n",
    "    \"res_Stadt Heidelberg.csv\",\n",
    "    #\"res_Stadt Heilbronn.csv\",\n",
    "    \"res_Stadt Karlsruhe.csv\",\n",
    "    #\"res_Stadt Kirchheim unter Teck.csv\",\n",
    "    #\"res_Stadt Konstanz.csv\",\n",
    "    #\"res_Stadt Ludwisburg.csv\",\n",
    "    #\"res_Stadt Lörrach.csv\",\n",
    "    \"res_Stadt Mannheim.csv\",\n",
    "    #\"res_Stadt Offenburg.csv\",\n",
    "    \"res_Stadt Reutlingen.csv\",\n",
    "    #\"res_Stadt Singen.csv\",\n",
    "    \"res_Stadt Tübingen.csv\",\n",
    "    \"res_Stadt Ulm.csv\",\n",
    "    #\"res_Stadtverwaltung Aalen.csv\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for file in csv_files:\n",
    "    city = file.replace(\"res_\", \"\").replace(\".csv\", \"\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    # Extract weekly seasonal component\n",
    "    df_weekly = pd.DataFrame({\n",
    "        \"weekday\": df[\"timestamp\"].dt.dayofweek,  # 0=Monday, 6=Sunday\n",
    "        \"hour\": df[\"timestamp\"].dt.hour,\n",
    "        \"seasonal_168\": df[\"seasonal_168\"]\n",
    "    })\n",
    "\n",
    "    # Compute the **average value for each hour of the week**\n",
    "    weekly_pattern = df_weekly.groupby([\"weekday\", \"hour\"])[\"seasonal_168\"].mean().unstack(level=0)\n",
    "\n",
    "    # Flatten to 0-167 hours\n",
    "    weekly_pattern_flat = weekly_pattern.values.flatten(order='F')  # Column-major to keep Mon->Sun order\n",
    "\n",
    "    plt.plot(range(168), weekly_pattern_flat, marker='o', label=city, alpha=0.7)\n",
    "\n",
    "plt.title(\"Average Weekly Bike Pattern Across Cities (Weekdays Aligned)\")\n",
    "plt.xlabel(\"Hour of Week (0–167)\")\n",
    "plt.ylabel(\"Average Seasonal_168 Effect\")\n",
    "plt.xticks(range(0, 168, 12))\n",
    "plt.grid(True)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "d8e3788cdd8b70da",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "csv_files = [\n",
    "    \"res_Landeshauptstadt Stuttgart.csv\",\n",
    "    \"res_Ravensburg TWS GmbH and Co KG.csv\",\n",
    "    \"res_Stadt Freiburg.csv\",\n",
    "    \"res_Stadt Heidelberg.csv\",\n",
    "    \"res_Stadt Heilbronn.csv\",\n",
    "    \"res_Stadt Karlsruhe.csv\",\n",
    "    \"res_Stadt Kirchheim unter Teck.csv\",\n",
    "    \"res_Stadt Konstanz.csv\",\n",
    "    \"res_Stadt Ludwisburg.csv\",\n",
    "    \"res_Stadt Lörrach.csv\",\n",
    "    \"res_Stadt Mannheim.csv\",\n",
    "    \"res_Stadt Offenburg.csv\",\n",
    "    \"res_Stadt Reutlingen.csv\",\n",
    "    \"res_Stadt Singen.csv\",\n",
    "    \"res_Stadt Tübingen.csv\",\n",
    "    \"res_Stadt Ulm.csv\",\n",
    "    \"res_Stadtverwaltung Aalen.csv\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "for file in csv_files:\n",
    "    city = file.replace(\"res_\", \"\").replace(\".csv\", \"\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    # Extract yearly seasonal component\n",
    "    df_yearly = pd.DataFrame({\n",
    "        \"month\": df[\"timestamp\"].dt.month,\n",
    "        \"seasonal_8766\": df[\"seasonal_8766\"]\n",
    "    })\n",
    "\n",
    "    # Aggregate by month\n",
    "    monthly_pattern = df_yearly.groupby(\"month\")[\"seasonal_8766\"].mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.plot(range(1, 13), monthly_pattern, marker='o', label=city, alpha=0.7)\n",
    "\n",
    "plt.title(\"Average Monthly Bike Pattern Across Cities\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Seasonal_8766 Effect\")\n",
    "plt.xticks(range(1, 13))\n",
    "plt.grid(True)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5a8e6af603fa8b53",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "csv_files = [\n",
    "    \"res_Landeshauptstadt Stuttgart.csv\",\n",
    "    \"res_Ravensburg TWS GmbH and Co KG.csv\",\n",
    "    \"res_Stadt Freiburg.csv\",\n",
    "    \"res_Stadt Heidelberg.csv\",\n",
    "    \"res_Stadt Heilbronn.csv\",\n",
    "    \"res_Stadt Karlsruhe.csv\",\n",
    "    \"res_Stadt Kirchheim unter Teck.csv\",\n",
    "    \"res_Stadt Konstanz.csv\",\n",
    "    \"res_Stadt Ludwisburg.csv\",\n",
    "    \"res_Stadt Lörrach.csv\",\n",
    "    \"res_Stadt Mannheim.csv\",\n",
    "    \"res_Stadt Offenburg.csv\",\n",
    "    \"res_Stadt Reutlingen.csv\",\n",
    "    \"res_Stadt Singen.csv\",\n",
    "    \"res_Stadt Tübingen.csv\",\n",
    "    \"res_Stadt Ulm.csv\",\n",
    "    \"res_Stadtverwaltung Aalen.csv\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for file in csv_files:\n",
    "    city = file.replace(\"res_\", \"\").replace(\".csv\", \"\")\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Ensure timestamp is datetime (optional for this calculation)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    # Compute variance explained by MSTL\n",
    "    # observed = trend + seasonal_24 + seasonal_168 + seasonal_8766 + residual\n",
    "    observed_var = df['trend'].add(df['seasonal_24'], fill_value=0) \\\n",
    "        .add(df['seasonal_168'], fill_value=0) \\\n",
    "        .add(df['seasonal_8766'], fill_value=0) \\\n",
    "        .add(df['residual'], fill_value=0).var()  # just for sanity, should equal df.sum^2 variance\n",
    "\n",
    "    residual_var = df['residual'].var()\n",
    "\n",
    "    variance_explained = 1 - residual_var / observed_var\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"City\": city,\n",
    "        \"Residual Variance\": residual_var,\n",
    "        \"Variance Explained\": variance_explained\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "variance_table = pd.DataFrame(results)\n",
    "\n",
    "# Sort by variance explained\n",
    "variance_table = variance_table.sort_values(by=\"Variance Explained\", ascending=False)\n",
    "\n",
    "print(variance_table)"
   ],
   "id": "39600f52e249ce",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "csv_files = [\n",
    "    \"res_Landeshauptstadt Stuttgart.csv\",\n",
    "    \"res_Ravensburg TWS GmbH and Co KG.csv\",\n",
    "    \"res_Stadt Freiburg.csv\",\n",
    "    \"res_Stadt Heidelberg.csv\",\n",
    "    \"res_Stadt Heilbronn.csv\",\n",
    "    \"res_Stadt Karlsruhe.csv\",\n",
    "    \"res_Stadt Kirchheim unter Teck.csv\",\n",
    "    \"res_Stadt Konstanz.csv\",\n",
    "    \"res_Stadt Ludwisburg.csv\",\n",
    "    \"res_Stadt Lörrach.csv\",\n",
    "    \"res_Stadt Mannheim.csv\",\n",
    "    \"res_Stadt Offenburg.csv\",\n",
    "    \"res_Stadt Reutlingen.csv\",\n",
    "    \"res_Stadt Singen.csv\",\n",
    "    \"res_Stadt Tübingen.csv\",\n",
    "    \"res_Stadt Ulm.csv\",\n",
    "    \"res_Stadtverwaltung Aalen.csv\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for file in csv_files:\n",
    "    city = file.replace(\"res_\", \"\").replace(\".csv\", \"\")\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "    # Residual metrics\n",
    "    residual_std = df['residual'].std()  # Standard deviation\n",
    "    residual_rms = (df['residual'] ** 2).mean() ** 0.5  # Root-mean-square\n",
    "\n",
    "    results.append({\n",
    "        \"City\": city,\n",
    "        \"Residual Std\": residual_std,\n",
    "        \"Residual RMS\": residual_rms\n",
    "    })\n",
    "\n",
    "# Create table\n",
    "residual_table = pd.DataFrame(results)\n",
    "residual_table = residual_table.sort_values(by=\"Residual Std\")  # sort by residual size\n",
    "print(residual_table)\n"
   ],
   "id": "ff72441ca4c52374",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file = \"data/mstl_results/res_Stadt Freiburg.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "\n",
    "# Compute the MSTL sum (without residual)\n",
    "mstl_sum = df['trend'] + df['seasonal_24'] + df['seasonal_168'] + df['seasonal_8766']\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot observed values\n",
    "plt.plot(df['timestamp'], mstl_sum + df['residual'], label=\"Observed\", color='black', alpha=0.8)\n",
    "\n",
    "# Plot MSTL sum\n",
    "plt.plot(df['timestamp'], mstl_sum, label=\"Trend + Seasonalities (MSTL sum)\", color='blue', alpha=0.7)\n",
    "\n",
    "# Plot residuals (shifted for visibility)\n",
    "plt.plot(df['timestamp'], df['residual'], label=\"Residuals\", color='red', alpha=0.5)\n",
    "\n",
    "plt.title(\"Observed vs MSTL Components – Stadt Freiburg\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Normalized Bike Counts\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f193e40bbf960418",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "csv_files = [\n",
    "    #\"res_Landeshauptstadt Stuttgart.csv\",\n",
    "    #\"res_Ravensburg TWS GmbH and Co KG.csv\",\n",
    "    \"res_Stadt Freiburg.csv\",\n",
    "    #\"res_Stadt Heidelberg.csv\",\n",
    "    #\"res_Stadt Heilbronn.csv\",\n",
    "    #\"res_Stadt Karlsruhe.csv\",\n",
    "    #\"res_Stadt Kirchheim unter Teck.csv\",\n",
    "    #\"res_Stadt Konstanz.csv\",\n",
    "    #\"res_Stadt Ludwisburg.csv\",\n",
    "    #\"res_Stadt Lörrach.csv\",\n",
    "    #\"res_Stadt Mannheim.csv\",\n",
    "    #\"res_Stadt Offenburg.csv\",\n",
    "    #\"res_Stadt Reutlingen.csv\",\n",
    "    #\"res_Stadt Singen.csv\",\n",
    "    #\"res_Stadt Tübingen.csv\",\n",
    "    #\"res_Stadt Ulm.csv\",\n",
    "    #\"res_Stadtverwaltung Aalen.csv\"\n",
    "]\n",
    "\n",
    "# Path to weather data\n",
    "weather_df = pd.read_csv(\"data\\\\weather_data.csv\")\n",
    "weather_df.rename(columns={'date': 'timestamp'}, inplace=True)\n",
    "weather_df['timestamp'] = pd.to_datetime(weather_df['timestamp'], utc=True)\n",
    "\n",
    "# Prepare a container for merged results\n",
    "merged_results = pd.DataFrame()\n",
    "for file in csv_files:\n",
    "    city = file.replace(\"res_\", \"\").replace(\".csv\", \"\").strip()\n",
    "\n",
    "    # Load MSTL\n",
    "    df = pd.read_csv(\"data\\\\mstl_results\\\\\" + file)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "    city_weather = weather_df[weather_df['city'] == city].copy()\n",
    "\n",
    "    # Merge\n",
    "    merged = pd.merge(df, city_weather, left_on=['timestamp', 'city'], right_on=['timestamp', 'city'], how='left')\n",
    "\n",
    "    # Temperature categories\n",
    "    merged['temp_category'] = pd.cut(\n",
    "        merged['apparent_temperature'],\n",
    "        bins=[-float('inf'), 5, 25, float('inf')],\n",
    "        labels=['cold', 'moderate', 'hot']\n",
    "    )\n",
    "\n",
    "    # Rain categories\n",
    "    merged['rain_category'] = pd.cut(\n",
    "        merged['rain'],\n",
    "        bins=[-0.01, 0, 2, 5, float('inf')],\n",
    "        labels=['no_rain', 'light_rain', 'moderate_rain', 'heavy_rain']\n",
    "    )\n",
    "\n",
    "    # Snow categories\n",
    "    merged['snow_category'] = pd.cut(\n",
    "        merged['snowfall'],\n",
    "        bins=[-0.01, 0, 2, float('inf')],\n",
    "        labels=['no_snow', 'light_snow', 'heavy_snow']\n",
    "    )\n",
    "\n",
    "    # Extreme heat / freezing flags\n",
    "    merged['extreme_heat'] = merged['apparent_temperature'] > 35\n",
    "    merged['freezing'] = merged['apparent_temperature'] < 0\n",
    "\n",
    "    # Store merged city data\n",
    "    merged.drop(\n",
    "        columns=['trend', 'seasonal_24', 'seasonal_168', 'seasonal_8766', 'apparent_temperature', 'temperature_2m',\n",
    "                 'rain', 'snowfall'], inplace=True)\n",
    "    merged_results = pd.concat([merged_results, merged], ignore_index=True)\n",
    "\n",
    "print(merged_results)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Box plot for residuals vs temperature category\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(data=merged_results, x='temp_category', y='residual')\n",
    "plt.title(\"Residuals by Temperature Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Box plot for residuals vs rain category\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(data=merged_results, x='rain_category', y='residual')\n",
    "plt.title(\"Residuals by Rain Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Box plot for residuals vs snow category\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(data=merged_results, x='snow_category', y='residual')\n",
    "plt.title(\"Residuals by Snow Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Violin plot for residuals vs temperature category\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.violinplot(data=merged_results, x='temp_category', y='residual', inner=\"quart\")\n",
    "plt.title(\"Residuals Distribution by Temperature Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Violin plot for residuals vs rain category\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.violinplot(data=merged_results, x='rain_category', y='residual', inner=\"quart\")\n",
    "plt.title(\"Residuals Distribution by Rain Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Violin plot for residuals vs snow category\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.violinplot(data=merged_results, x='snow_category', y='residual', inner=\"quart\")\n",
    "plt.title(\"Residuals Distribution by Snow Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "temp_d = d.copy()\n",
    "temp_d['temp_category'] = pd.cut(\n",
    "    temp_d['apparent_temperature'],\n",
    "    bins=[-float('inf'), 5, 25, float('inf')],\n",
    "    labels=['cold', 'moderate', 'hot']\n",
    ")\n",
    "\n",
    "# Rain categories\n",
    "temp_d['rain_category'] = pd.cut(\n",
    "    temp_d['rain'],\n",
    "    bins=[-0.01, 0, 2, 5, float('inf')],\n",
    "    labels=['no_rain', 'light_rain', 'moderate_rain', 'heavy_rain']\n",
    ")\n",
    "\n",
    "# Snow categories\n",
    "temp_d['snow_category'] = pd.cut(\n",
    "    temp_d['snowfall'],\n",
    "    bins=[-0.01, 0, 2, float('inf')],\n",
    "    labels=['no_snow', 'light_snow', 'heavy_snow']\n",
    ")\n",
    "\n",
    "# Extreme heat / freezing flags\n",
    "temp_d['extreme_heat'] = temp_d['apparent_temperature'] > 35\n",
    "temp_d['freezing'] = temp_d['apparent_temperature'] < 0\n",
    "# Violin plot for residuals vs temperature category\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.violinplot(data=temp_d, x='temp_category', y='median_count', inner=\"quart\")\n",
    "plt.title(\"Residuals Distribution by Temperature Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Violin plot for residuals vs rain category\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.violinplot(data=temp_d, x='rain_category', y='median_count', inner=\"quart\")\n",
    "plt.title(\"Residuals Distribution by Rain Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Violin plot for residuals vs snow category\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.violinplot(data=temp_d, x='snow_category', y='median_count', inner=\"quart\")\n",
    "plt.title(\"Residuals Distribution by Snow Category\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "d71b6145e08c1ad4",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "city = \"Stadt Freiburg\"\n",
    "periods = [24, 168, 8766]\n",
    "res = performMSTL(d, city, on_column=\"median_count\", use_boxcox=True, lambda_bc=0, periods=periods)\n",
    "plotMSTLResults(res, city)"
   ],
   "id": "d8af9f90f7f7fe8d",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "city = \"Stadt Freiburg\"\n",
    "periods = [24, 168, 8766]\n",
    "res2 = performMSTL(d, city, on_column=\"median_count\", use_boxcox=True, periods=periods)\n",
    "plotMSTLResults(res2, city)"
   ],
   "id": "fa9fdb0f008407f",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "city = \"Stadt Freiburg\"\n",
    "periods = [24, 168, 8766]\n",
    "res3 = performMSTL(d, city, on_column=\"median_count\", use_boxcox=False, periods=periods)\n",
    "plotMSTLResults(res3, city)"
   ],
   "id": "5a967c0902fbbbe1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:11:09.601980Z",
     "start_time": "2025-12-23T13:10:52.432871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "city = \"Stadt Freiburg\"\n",
    "periods = [24, 168, 8766]\n",
    "counter_id = 100004595\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "\n",
    "d_t = d.copy()\n",
    "d_city = d_t[(d_t[\"city\"] == city) & (d_t[\"counter_site_id\"] == counter_id)].copy()\n",
    "d_t[\"timestamp\"] = pd.to_datetime(d_t[\"timestamp\"], utc=True)\n",
    "d_city = d_city.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
    "y = d_city[\"count\"].astype(float)\n",
    "\n",
    "y_pos = y + 1  # ensure positivity\n",
    "\n",
    "#y_bc, lambda_bc = boxcox(y_pos)\n",
    "\n",
    "#y_bc = pd.Series(y_bc, index=y.index)\n",
    "\n",
    "#print(\"Estimated Box–Cox λ:\", lambda_bc)\n",
    "print(y)\n"
   ],
   "id": "9bd463fb3f938f40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp\n",
      "2012-12-31 23:00:00+00:00     51.0\n",
      "2013-01-01 00:00:00+00:00    117.0\n",
      "2013-01-01 01:00:00+00:00    131.0\n",
      "2013-01-01 02:00:00+00:00    145.0\n",
      "2013-01-01 03:00:00+00:00     76.0\n",
      "                             ...  \n",
      "2025-12-14 18:00:00+00:00    310.0\n",
      "2025-12-14 19:00:00+00:00    222.0\n",
      "2025-12-14 20:00:00+00:00    211.0\n",
      "2025-12-14 21:00:00+00:00    125.0\n",
      "2025-12-14 22:00:00+00:00     94.0\n",
      "Name: count, Length: 113531, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-12-23T13:11:57.989426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from statsmodels.tsa.stl._stl import STL\n",
    "\n",
    "stl_trend = STL(\n",
    "    y,\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "res_trend = stl_trend.fit()\n",
    "trend = res_trend.trend\n",
    "\n",
    "# detrended series\n",
    "residual = y - trend\n"
   ],
   "id": "5cc467de94a8992d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:09:49.538257Z",
     "start_time": "2025-12-23T13:09:49.530268Z"
    }
   },
   "cell_type": "code",
   "source": "print(d_city[\"count\"].astype(float))",
   "id": "648cb4eee4969464",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timezone.utc"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T12:52:31.917095Z",
     "start_time": "2025-12-23T12:52:05.641973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seasonal_components = {}\n",
    "periods = [24, 168, 8766]\n",
    "\n",
    "for p in sorted(periods):\n",
    "    stl = STL(\n",
    "        residual,\n",
    "        period=p,\n",
    "        seasonal=p+1,   # common choice: seasonal window ≈ period\n",
    "        trend=2*p +1,      # effectively disables trend estimation\n",
    "        robust=True\n",
    "    )\n",
    "\n",
    "    res = stl.fit()\n",
    "    seasonal = res.seasonal\n",
    "\n",
    "    seasonal_components[p] = seasonal\n",
    "\n",
    "    # remove this seasonality before next iteration\n",
    "    residual = residual - seasonal\n",
    "    print(\"finished:\",p)\n",
    "\n",
    "remainder = residual\n"
   ],
   "id": "d35f834576899568",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: 24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(periods):\n\u001B[32m      5\u001B[39m     stl = STL(\n\u001B[32m      6\u001B[39m         residual,\n\u001B[32m      7\u001B[39m         period=p,\n\u001B[32m   (...)\u001B[39m\u001B[32m     10\u001B[39m         robust=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     11\u001B[39m     )\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m     res = \u001B[43mstl\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     14\u001B[39m     seasonal = res.seasonal\n\u001B[32m     16\u001B[39m     seasonal_components[p] = seasonal\n",
      "\u001B[36mFile \u001B[39m\u001B[32mstatsmodels/tsa/stl/_stl.pyx:347\u001B[39m, in \u001B[36mstatsmodels.tsa.stl._stl.STL.fit\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mstatsmodels/tsa/stl/_stl.pyx:640\u001B[39m, in \u001B[36mstatsmodels.tsa.stl._stl.STL._rwts\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:868\u001B[39m, in \u001B[36mpartition\u001B[39m\u001B[34m(a, kth, axis, kind, order)\u001B[39m\n\u001B[32m    866\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    867\u001B[39m     a = asanyarray(a).copy(order=\u001B[33m\"\u001B[39m\u001B[33mK\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m868\u001B[39m \u001B[43ma\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpartition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkind\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkind\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    869\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "reconstructed = trend.copy()\n",
    "for s in seasonal_components.values():\n",
    "    reconstructed += s\n",
    "reconstructed += remainder\n",
    "\n",
    "# should be ~ zero (numerical noise only)\n",
    "max_error = np.nanmax(np.abs(reconstructed - y))\n",
    "print(\"Max reconstruction error:\", max_error)\n"
   ],
   "id": "8ba1ebe91fdc5941"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "429d13df0c3fc00f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
